---
title: 离线推理
---

[\*在线运行 vLLM 入门教程：零基础分步指南](https://openbayes.com/console/public/tutorials/rXxb5fZFr29?utm_source=vLLM-CNdoc&utm_medium=vLLM-CNdoc-V1&utm_campaign=vLLM-CNdoc-V1-25ap)

离线推理示例展示了如何在离线环境中使用 vLLM，以批量方式查询模型进行预测。我们建议从 [Basic](https://docs.vllm.ai/en/latest/getting_started/examples/basic.html) 开始。

示例

- [Audio Language](https://docs.vllm.ai/en/latest/getting_started/examples/audio_language.html)
- [Basic](https://docs.vllm.ai/en/latest/getting_started/examples/basic.html)
- [Chat With Tools](https://docs.vllm.ai/en/latest/getting_started/examples/chat_with_tools.html)
- [CPU Offload Lmcache](https://docs.vllm.ai/en/latest/getting_started/examples/cpu_offload_lmcache.html)
- [Data Parallel](https://docs.vllm.ai/en/latest/getting_started/examples/data_parallel.html)
- [Disaggregated Prefill](https://docs.vllm.ai/en/latest/getting_started/examples/disaggregated_prefill.html)
- [Disaggregated Prefill Lmcache](https://docs.vllm.ai/en/latest/getting_started/examples/disaggregated_prefill_lmcache.html)
- [Distributed](https://docs.vllm.ai/en/latest/getting_started/examples/distributed.html)
- [Eagle](https://docs.vllm.ai/en/latest/getting_started/examples/eagle.html)
- [Encoder Decoder](https://docs.vllm.ai/en/latest/getting_started/examples/encoder_decoder.html)
- [Encoder Decoder Multimodal](https://docs.vllm.ai/en/latest/getting_started/examples/encoder_decoder_multimodal.html)
- [LLM Engine Example](https://docs.vllm.ai/en/latest/getting_started/examples/llm_engine_example.html)
- [LoRA With Quantization Inference](https://docs.vllm.ai/en/latest/getting_started/examples/lora_with_quantization_inference.html)
- [Mistral-Small](https://docs.vllm.ai/en/latest/getting_started/examples/mistral-small.html)
- [MLPSpeculator](https://docs.vllm.ai/en/latest/getting_started/examples/mlpspeculator.html)
- [MultiLoRA Inference](https://docs.vllm.ai/en/latest/getting_started/examples/multilora_inference.html)
- [Neuron](https://docs.vllm.ai/en/latest/getting_started/examples/neuron.html)
- [Neuron INT8 Quantization](https://docs.vllm.ai/en/latest/getting_started/examples/neuron_int8_quantization.html)
- [Offline Inference with the OpenAI Batch file format](https://docs.vllm.ai/en/latest/getting_started/examples/openai.html)
- [Prefix Caching](https://docs.vllm.ai/en/latest/getting_started/examples/prefix_caching.html)
- [Prithvi Geospatial Mae](https://docs.vllm.ai/en/latest/getting_started/examples/prithvi_geospatial_mae.html)
- [Profiling](https://docs.vllm.ai/en/latest/getting_started/examples/profiling.html)
- [vLLM TPU Profiling](https://docs.vllm.ai/en/latest/getting_started/examples/profiling_tpu.html)
- [Reproduciblity](https://docs.vllm.ai/en/latest/getting_started/examples/reproduciblity.html)
- [RLHF](https://docs.vllm.ai/en/latest/getting_started/examples/rlhf.html)
- [RLHF Colocate](https://docs.vllm.ai/en/latest/getting_started/examples/rlhf_colocate.html)
- [RLHF Utils](https://docs.vllm.ai/en/latest/getting_started/examples/rlhf_utils.html)
- [Save Sharded State](https://docs.vllm.ai/en/latest/getting_started/examples/save_sharded_state.html)
- [Simple Profiling](https://docs.vllm.ai/en/latest/getting_started/examples/simple_profiling.html)
- [Structured Outputs](https://docs.vllm.ai/en/latest/getting_started/examples/structured_outputs.html)
- [Torchrun Example](https://docs.vllm.ai/en/latest/getting_started/examples/torchrun_example.html)
- [TPU](https://docs.vllm.ai/en/latest/getting_started/examples/tpu.html)
- [Vision Language](https://docs.vllm.ai/en/latest/getting_started/examples/vision_language.html)
- [Vision Language Embedding](https://docs.vllm.ai/en/latest/getting_started/examples/vision_language_embedding.html)
- [Vision Language Multi Image](https://docs.vllm.ai/en/latest/getting_started/examples/vision_language_multi_image.html)
