---
title: 量化
---

[\*在线运行 vLLM 入门教程：零基础分步指南](https://openbayes.com/console/public/tutorials/rXxb5fZFr29?utm_source=vLLM-CNdoc&utm_medium=vLLM-CNdoc-V1&utm_campaign=vLLM-CNdoc-V1-25ap)

量化通过牺牲模型精度来换取更小的内存占用，从而使得大型模型能够在更广泛的设备上运行。

## 目录

- 支持硬件
- AutoAWQ
- BitsAndBytes
- GGUF
- INT4 W4A16
- INT8 W8A8
- FP8 W8A8
- 量化 KV 缓存
